[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Work of the UNECE High-Level Group for the Modernisation of Official Statistics\nOutputs of the UNEC Statistical Modernisation Unit\nThe Awesome List of Official Statistics\nThe ModernStats Carpentries (note: the lessons are under construction)\n\nPython / Git / R\n\nESS Principles on Open-Source Software\nSDMX OS Resources\n\n\n\n\n…\n\n\n\n\n\n\nNote\n\n\n\nWeb site under construction"
  },
  {
    "objectID": "resources.html#links",
    "href": "resources.html#links",
    "title": "Resources",
    "section": "",
    "text": "Work of the UNECE High-Level Group for the Modernisation of Official Statistics\nOutputs of the UNEC Statistical Modernisation Unit\nThe Awesome List of Official Statistics\nThe ModernStats Carpentries (note: the lessons are under construction)\n\nPython / Git / R\n\nESS Principles on Open-Source Software\nSDMX OS Resources"
  },
  {
    "objectID": "resources.html#papers",
    "href": "resources.html#papers",
    "title": "Resources",
    "section": "",
    "text": "…\n\n\n\n\n\n\nNote\n\n\n\nWeb site under construction"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "HLG-MOS Open Source Software",
    "section": "",
    "text": "Attribution 4.0 International\n=======================================================================\nCreative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.\nUsing Creative Commons Public Licenses\nCreative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.\n Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n=======================================================================\nCreative Commons Attribution 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\n\nreproduce and Share the Licensed Material, in whole or in part; and\nproduce, reproduce, and Share Adapted Material.\n\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)\n\nnever produces Adapted Material.\n\nDownstream recipients.\n\nOffer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nNo downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\n\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\n\nretain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nindicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nindicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\n\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\nIf You Share Adapted Material You produce, the Adapter’s License You apply must not prevent recipients of the Adapted Material from complying with this Public License.\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material; and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS, IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.\nTO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION, NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT, INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES, COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n=======================================================================\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org.\n\n\n\n Back to top"
  },
  {
    "objectID": "charter.html",
    "href": "charter.html",
    "title": "UNECE HLG-MOS Open-Source Software Charter for Official Statistics",
    "section": "",
    "text": "Important\n\n\n\nThe text herein is currently under draft and should by no means be considered finalised.\nAny references to endorsement by the UNECE HLG-MOS or any other body are proposed and not valid as of the time of writing."
  },
  {
    "objectID": "charter.html#opening-statement",
    "href": "charter.html#opening-statement",
    "title": "UNECE HLG-MOS Open-Source Software Charter for Official Statistics",
    "section": "Opening Statement",
    "text": "Opening Statement\nWe recognise open source software (OSS) as essential for modern statistical production, promoting transparency in methodology and fostering international collaboration in developing and supporting the production of official statistics.\nOpen source solutions enable national statistical offices (NSOs) to develop, validate, and share statistical methods while ensuring reproducibility of official statistics. The transparent nature of open source software allows for peer review of statistical procedures, thereby strengthening the credibility of official statistics. Sharing software as open source software (OSS) is consistent with the transparency principle of the Fundamental Principles of Official Statistics (principle 3) and the National Quality Assurance Framework (principle 6).\nReuse of software assets across organisations in the statistical process chain is beneficial. Reducing duplication of efforts through co-investments increases efficiency, and sharing statistical code and tools between NSOs creates a collaborative ecosystem that accelerates innovation in official statistics, while facilitating methodological harmonisation across countries. These approaches ensure efficient use of public resources while maintaining the independence and scientific integrity of national statistical systems. Therefore, by adopting and developing open source tools, NSOs can build flexible, cost-effective statistical infrastructures that can adapt to new and emerging data sources and methodological innovations, while building trust through transparency in statistical production.\nA statistical open source community is most effective and innovative if it works from a common understanding across statistical organisations of the underlying drivers for open source. For this reason, it is necessary to identify the basic principles underlying open source in official statistics.\nWe therefore endorse using the following Principles on Open Source Software in official statistics in both the production of software, and the adoption of software for statistical production. 1"
  },
  {
    "objectID": "charter.html#principles-under-process-of-ces-endorsement",
    "href": "charter.html#principles-under-process-of-ces-endorsement",
    "title": "UNECE HLG-MOS Open-Source Software Charter for Official Statistics",
    "section": "Principles (under process of CES endorsement)",
    "text": "Principles (under process of CES endorsement)\n\n1. OSS by default\n\nStatement\nIn the production of official statistics we prefer the use of open source software solutions over closed software solutions. Moreover we share our software solutions as open source.\n\n\nRationale\nThis principle contributes to the core values of official statistics, such as transparency and independence in the way we produce statistics and striving for high quality and reproducibility. Using and sharing open source software increases the transparency of our work and avoids black boxes in the implementation of official statistics.\n\n\nImplications\nThis means that when implementing, redesigning or creating new processes, open source software solutions have preference. Only when no viable open source solutions exist should an NSO deviate from the standard OSS option. Likewise, sharing as open source is the default, but it is possible to deviate from this in justified cases. For NSOs this means that the methods used in the production of official statistics are not only described, but also that the code used to actually apply the method is shared as OSS. For international organisations this means openness about how international aggregates are computed via OSS solutions.\n\n\n\n2. Work in the open\n\nStatement\nWe start our projects in the open from the beginning and clearly mark maturity status.\n\n\nRationale\nMany projects have the intention to publish results as open source but have difficulty deciding on the best time to do so. It might feel uncomfortable to put early ideas and rough implementation sketches on-line, but on the other hand sharing it too late prevents others from providing valuable comments and ideas or volunteering to work together on the project. To circumvent this dilemma we start working in the open right from the beginning wherever possible and clearly mark and update our project’s development phase over time.\n\n\nImplications\nThis means that it is recommended and accepted to start development projects in the public domain. We clearly show the development status, which may vary from pre-alpha to stable and proven by showing a public roadmap, public source code repository, a public backlog of features, issues, bugs etc.\n\n\n\n3. Improve and give back\n\nStatement\nWe improve existing open source solutions rather than decide to create new solutions and we give our improvements back to the respective open source community.\n\n\nRationale\nThere are cases where existing open source solutions do not cover one-to-one the functionality needed in official statistics. The quickest way to address this is to copy a solution, adapt it and use it. However, the improvements made in the original solution will not be merged into the copy and our improvements made to the copy will not be visible in a wider context. Therefore, we strive to give back our improvements to the open source community as change requests or suggestions even if it takes additional resources to do so. In the end, this is an investment in the effectiveness and efficiency of the official statistics community as a whole.\n\n\nImplications\nThis means that statistical organisations actively search for solutions that can be reused instead of having to create new solutions themselves. Even if a solution does not exactly fit the required functionality, it can be examined for how it could be improved while keeping the intended functionality in mind, or even extending such functionality. This also applies for partial solutions such as code snippets and models (including machine learning models) that could be valuable for others. The changes or enhancements should be tested, documented, and returned to the respective community to decide on whether to integrate them into their solution.\n\n\n\n4. Think generic statistical building blocks\n\nStatement\nIn our open source work we strive for re-usable generic functional building blocks that support well-defined methodologies in statistical processes.\n\n\nRationale\nPublishing source code as open source is not sufficient by itself for effective reuse in the global official statistics community. It is necessary to think about the design of what is to be shared and to identify generic statistical building blocks that can be used in different contexts. Therefore, we design the software from the point of view of the intended users and in such a way that it can be reused in as many statistical domains or organisations as possible. This helps maintain complex statistical processes and high-quality official statistics.\n\n\nImplications\nThis means that monolithic applications are componentised as much as possible into generic configurable statistical building blocks. We put statistical functionality into code and make statistical expertise configurable. We make these components as generic as possible in time, across statistical domains and across statistical organisations. For individual NSOs this means that not just its own statistical production process should be kept in mind when developing tools, but also the possible wider applicability. International organisations should actively encourage the development and sharing of generic OSS solutions within their domain of expertise.\n\n\n\n5. Test, package and document\n\nStatement\nWe test, package and document our open source software for easy reuse.\n\n\nRationale\nRe-using generic statistical software in the official statistics community is not always easy due to differences in statistical processes, technological environments, and ways of working. Testing our software for functionality and security and packaging our software with good documentation is of utmost importance as it improves the chances of reuse. General purpose package management systems offer versioning and documentation facilities to share generic statistical software. The use of such packaging systems helps to maintain complex statistical processes and ensure high-quality official statistics.\n\n\nImplications\nThis means that we invest in testing, security scanning, packaging and documentation to enable reuse. Security patches are applied as soon as possible. Documentation is designed from the point of view of a statistical user, keeping it concise, understandable but also complete and covering at least the basic functionality and a complete API reference. Packaging is a key success criterion for open source projects. Larger projects should adopt modern approaches such as containerisation, automating as much as possible. Smaller projects may also follow these practices. Each package is downloadable without registration, can be installed with minimal effort, and has a minimal viable example that can be executed. Dependencies are managed and minimised as much as possible . Versioning is implemented according to the principles of the respective package exchange platform with a preference for semantic versioning. Security patches are implemented with priority. For individual NSOs this means that published OSS software is maintained and updated according to the policies of the relevant platforms, e.g., CRAN. International organisations should play an active role in sharing knowledge about testing and packaging, as well as documentation policies in their domain of expertise.\n\n\n\n6. Choose permissive\n\nStatement\nWe choose the most permissive OS licence possible for sharing our software.\n\n\nRationale\nRe-using software is in the common interest of the official statistics community. Reuse of our software not only enhances efficiency but also improves the quality of the software by allowing the wider user community to contribute to its development and maintenance. To maximise reuse by others it is necessary to choose an OS licence that maximally allows reuse, and minimises conflicts with other licences. This is known as “permissive”. When choosing the appropriate OS licence we strive for maximum reuse.\n\n\nImplications\nThis means that when sharing software we opt for a permissive licence (e.g. Apache 2.0/MIT) over a “copyleft” licence, taking into legal, organisational and societal considerations. Mandatory acknowledgement / attribution of sources and authors is a viable additional option.\n\n\n\n7. Promote\n\nStatement\nWe invest in promoting new developments or improvements of our open source software within the official statistics community, and where applicable in a wider context.\n\n\nRationale\nReuse of generic software will not happen if no one knows what can be reused. On the other hand, it is difficult to know beforehand what the value of our software is for others. The only way forward is to communicate, even if we have no idea whether it can be used in a wider context. We promote our software in an honest and concise way, mentioning its core functionality. We let the public know our plans for new developments and improvements and are open to suggestions for improvements.\n\n\nImplications\nThis means working together on communication facilities targeted at the open source community. A community-driven approach of sharing knowledge, tackling possible OS building blocks, and the application of OS in statistical production should be preferred to centrally maintained repositories. A centrally maintained repository of software tools can quickly become outdated, and collecting and organising information from the community can be an immense effort. Therefore, such a repository should be maintained by the community as a whole. For individual NSOs this means actively participating in the OSS community by attending events, joining relevant forums, etc. International organisations should play an active role in the organisation of the statistical OSS community in their domains of expertise."
  },
  {
    "objectID": "charter.html#footnotes",
    "href": "charter.html#footnotes",
    "title": "UNECE HLG-MOS Open-Source Software Charter for Official Statistics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe principles were initially developed as “ESS Principles on Open Source Software” (https://os4os.pages.code.europa.eu/pbbp/principles.html) by the group on Open Source for Official Statistics (https://os4os.pages.code.europa.eu/pbbp) and adjusted for the global context.↩︎"
  },
  {
    "objectID": "background.html",
    "href": "background.html",
    "title": "Background",
    "section": "",
    "text": "Open-source software is essential for modern statistical production, fostering transparency in methodology and promoting international collaboration in developing and supporting the production of official statistics.\nConsequently, the Charter and its principles herein on open-source software in official statistics in both the production of software, and the adoption of software for statistical production, have been drafted under the HLG-MOS Open-Source Software Project 2024 for consideration of endorsement by the UNECE HLG-MOS.\nBe aware that content found here is currently under draft and should not be considered final copy at the current time of writing."
  },
  {
    "objectID": "background.html#who-we-are",
    "href": "background.html#who-we-are",
    "title": "Background",
    "section": "Who we are",
    "text": "Who we are\nThis site is an important deliverable of the Statistical Open Source Software project that was conducted over the 2024 period, and mandated by the UNECE High-Level Group for the Modernisation of Official Statistics (HLG-MOS) following its annual meeting in November 2023.\nThe project, led by Carlo Vaccari (UNECE Project Manager), was composed of around 30 experts, drawing from national statistics and other institutions as well as international organisations. The following experts kindly dedicated their time and contributed their knowledge, experience, and expertise to this project.\n\nCraig Lindenmayer (Australian Bureau of Statistics)\n\nKate Burnett-Isaacs (Infrastructure Canada), who lead the Governance & Maintenance sub-team\n\nMireille Paquette, Li Wang, Christie Glover, & Jonathan Wylie (Statistics Canada)\n\nMarcello D’Orazio, Lorenzo Asti, Francesco Isidori, Pierpaolo Massoli & Samanta Pietropaoli (Italian National Institute of Statistics)\n\nAkmaral Tokbergenova & Kairat Kipatov (Statistics Kazakhstan)\n\nOlav ten Bosch & Mark van der Loo (Statistics Netherlands)\n\nPubudu Senanayake & Kevin Townend (Statistics New Zealand)\n\nNevena Mitrovic, Aleksandra Skoko Despenic, Mira Nikic & Nikola Orlic (Statistical Office of the Republic of Serbia)\nKarl McKenzie, Martin Ralphs & Ken Rennoldson (UK ONS)\n\nMatyas Meszaros (Eurostat)\n\nJonathan Challener (OECD)\n\nIraj Namdarian (Council for Agricultural Research and Economics)\n\nInKyung Choi & Andrew Tait (UNECE)."
  },
  {
    "objectID": "background.html#target-audience",
    "href": "background.html#target-audience",
    "title": "Background",
    "section": "Target Audience",
    "text": "Target Audience\nThis site has been created to help guide NSOs and their staff who are interested in using, developing, and sharing statistical methods and tools openly while producing official statistics. .\n\n\n\n\n\n\nNote\n\n\n\nWeb site under construction"
  },
  {
    "objectID": "case_studies.html",
    "href": "case_studies.html",
    "title": "Case Studies",
    "section": "",
    "text": "Building a FOSS ecosystem for statistical data processing\nStatistics Netherlands\n\n\nStatistics Netherlands (CBS) has embraced the use of Free and Open Source Software for statistical production for more than a decade. A significant step in that direction was taken in 2010 when R was adopted as a strategic tool for data processing1. R is both a software tool for statistical data processing and a programming language that is extensible through R packages. These packages are typically published on the Comprehensive R Archive Network, which enforces a strict quality policy on code quality, documentation, and interoperability of packages.\nRecognising the need for production systems that are built out of composable and reusable (generic) modules, researchers at CBS started to both use and contribute packages to the R ecosystem. A major part of those contributions consist of R packages in the area of statistical data cleaning and data processing  2  3.\nOver time, these packages have been adopted both within Statistics Netherlands and outside. Within CBS, packages are used in the production of areas covering social and economic statistics, agriculture, international trade, education, environmental statistics, emissions, income, shipping, Short-Term-Statistics, recreation, museums, and many more. Outside statistics we have seen uptake of the packages by statistical institutes of Iceland, Denmark, Italy, Brasil, and probably many more. It is noteworthy that the US Department of Agriculture National Agricultural Statistical Service (USDA-NASS 4) is using CBS R packages to validate and clean data from large national surveys under American farmers.\n\n\n\nThe current ecosystem (Table 1) consists of a number of packages that integrate seamlessly. Not only because there is a shared technical platform (i.e., R), but also because careful thought was put in pegging out, with formal precision, what each fundamental processing step entails. Below we describe two examples demonstrating the extensibility and power of this modular approach.\nThe first example concerns data validation. Until about 2024, the act of checking data against domain knowledge, in the form of validation rules, was not recognised as a separate activity. In almost any available system this was either hard-coded by users or integrated in a larger data-editing system. Creating a separate package (called validate) with the sole purpose of defining, manipulating and executing data validation rules yielded the possibility of monitoring the progress of data quality along multiple statistical value chains using a single piece of software  5  6. Moreover, the rule management system of the package is reused in packages for error localisation (errorlocate), data correction (deductive) and aggregating based on dynamically defined data groupings (accumulate)  7  8  9.\nA second example is an imputation package (simputation) that allows users to combine (i.e., chain) a large number of popular imputation models in fall-through scenarios that are often used in economic statistics 10. The package allows for group-wise processing, where groups are statically defined. When the need arose to extend the functionality, it was possible to define a new add-on package (accumulate) that allows for grouping of data where the grouping is determined dynamically and depending on data circumstances. The fact that it was possible to add new, unanticipated functionality is a consequence of the careful design and separation of concerns when designing each individual module.\n\n\n\nTable 1. R-based open source ecosystem for statistical data processing\n\n\n\n\n\nR package\nDescription\n\n\nvalidate\nCheck validity of data based on user-defined rules.\n\n\ndcmodify\nAdapt erroneous data based on user-defined rules.\n\n\nerrorlocate\nFind the minimal number of erroneous data points.\n\n\nsimputation\nMany different imputation methods with a single easy to learn interface.\n\n\nrspa\nAdjust numerical records to fit equality and inequality restrictions.\n\n\ndeductive\nSolve data errors, using the data and validation rules.\n\n\nvalidatetools\nFind contradictions and redundancies in rule sets.\n\n\naccumulate\nGrouped aggregation, where grouping is dynamic and data-dependent.\n\n\nlumberjack\nAutomatically track changes in data for logging purposes  11  12.\n\n\nreclin2\nJoin datasets based on (multiple) possibly inexact keys  13.\n\n\n\nAll packages have been developed in the open, by hosting the code on open version control repositories (i.e., GitHub), presenting the work at conferences, publishing in scientific journals, and promoting usage and feedback from (potential) users. The uptake of packages by non-CBS users is facilitated by releasing the packages on a standardised release platform (i.e., CRAN), using permissive licences and paying attention to documentation. Feedback and contributions from users outside of Statistics Netherlands, and even from outside of the official statistics community, has substantially helped improve and generalise the software. The fact that software can be easily downloaded and installed makes it trivial for R users to give the software a try and the open development platforms facilitate reporting of questions, issues, or even contributing. It should in this respect be mentioned that contributions may range from things as simple as fixing typing errors in the documentation, to demonstrating new use cases, filing bug reports, or even fixing bugs or adding functionality.\n\n\n\nThe fact that the whole ecosystem has been developed in the open, as an open source project, has contributed crucially to the success on several levels.\nIn the first place there is a large FOSS community in R that provides help, a packaging system, and also an infrastructure for developing, testing, documenting and publishing packages. The fact that this infrastructure, including the presence of a global informal and helpful community, exists has been extremely helpful during design and development of the packages. The usefulness of being able to directly contact the people who develop the infrastructure one is using is hard to overstate.\nSecondly, publishing the packages in open source immediately gives a large audience the opportunity to try the product: given enough eyeballs, all bugs are shallow  14. Enthusiastic users are able to contribute new use cases, issues, and documentation, which overall has contributed to creating more general and more robust software."
  },
  {
    "objectID": "case_studies.html#Data-Cleaning",
    "href": "case_studies.html#Data-Cleaning",
    "title": "Case Studies",
    "section": "",
    "text": "Building a FOSS ecosystem for statistical data processing\nStatistics Netherlands\n\n\nStatistics Netherlands (CBS) has embraced the use of Free and Open Source Software for statistical production for more than a decade. A significant step in that direction was taken in 2010 when R was adopted as a strategic tool for data processing1. R is both a software tool for statistical data processing and a programming language that is extensible through R packages. These packages are typically published on the Comprehensive R Archive Network, which enforces a strict quality policy on code quality, documentation, and interoperability of packages.\nRecognising the need for production systems that are built out of composable and reusable (generic) modules, researchers at CBS started to both use and contribute packages to the R ecosystem. A major part of those contributions consist of R packages in the area of statistical data cleaning and data processing  2  3.\nOver time, these packages have been adopted both within Statistics Netherlands and outside. Within CBS, packages are used in the production of areas covering social and economic statistics, agriculture, international trade, education, environmental statistics, emissions, income, shipping, Short-Term-Statistics, recreation, museums, and many more. Outside statistics we have seen uptake of the packages by statistical institutes of Iceland, Denmark, Italy, Brasil, and probably many more. It is noteworthy that the US Department of Agriculture National Agricultural Statistical Service (USDA-NASS 4) is using CBS R packages to validate and clean data from large national surveys under American farmers.\n\n\n\nThe current ecosystem (Table 1) consists of a number of packages that integrate seamlessly. Not only because there is a shared technical platform (i.e., R), but also because careful thought was put in pegging out, with formal precision, what each fundamental processing step entails. Below we describe two examples demonstrating the extensibility and power of this modular approach.\nThe first example concerns data validation. Until about 2024, the act of checking data against domain knowledge, in the form of validation rules, was not recognised as a separate activity. In almost any available system this was either hard-coded by users or integrated in a larger data-editing system. Creating a separate package (called validate) with the sole purpose of defining, manipulating and executing data validation rules yielded the possibility of monitoring the progress of data quality along multiple statistical value chains using a single piece of software  5  6. Moreover, the rule management system of the package is reused in packages for error localisation (errorlocate), data correction (deductive) and aggregating based on dynamically defined data groupings (accumulate)  7  8  9.\nA second example is an imputation package (simputation) that allows users to combine (i.e., chain) a large number of popular imputation models in fall-through scenarios that are often used in economic statistics 10. The package allows for group-wise processing, where groups are statically defined. When the need arose to extend the functionality, it was possible to define a new add-on package (accumulate) that allows for grouping of data where the grouping is determined dynamically and depending on data circumstances. The fact that it was possible to add new, unanticipated functionality is a consequence of the careful design and separation of concerns when designing each individual module.\n\n\n\nTable 1. R-based open source ecosystem for statistical data processing\n\n\n\n\n\nR package\nDescription\n\n\nvalidate\nCheck validity of data based on user-defined rules.\n\n\ndcmodify\nAdapt erroneous data based on user-defined rules.\n\n\nerrorlocate\nFind the minimal number of erroneous data points.\n\n\nsimputation\nMany different imputation methods with a single easy to learn interface.\n\n\nrspa\nAdjust numerical records to fit equality and inequality restrictions.\n\n\ndeductive\nSolve data errors, using the data and validation rules.\n\n\nvalidatetools\nFind contradictions and redundancies in rule sets.\n\n\naccumulate\nGrouped aggregation, where grouping is dynamic and data-dependent.\n\n\nlumberjack\nAutomatically track changes in data for logging purposes  11  12.\n\n\nreclin2\nJoin datasets based on (multiple) possibly inexact keys  13.\n\n\n\nAll packages have been developed in the open, by hosting the code on open version control repositories (i.e., GitHub), presenting the work at conferences, publishing in scientific journals, and promoting usage and feedback from (potential) users. The uptake of packages by non-CBS users is facilitated by releasing the packages on a standardised release platform (i.e., CRAN), using permissive licences and paying attention to documentation. Feedback and contributions from users outside of Statistics Netherlands, and even from outside of the official statistics community, has substantially helped improve and generalise the software. The fact that software can be easily downloaded and installed makes it trivial for R users to give the software a try and the open development platforms facilitate reporting of questions, issues, or even contributing. It should in this respect be mentioned that contributions may range from things as simple as fixing typing errors in the documentation, to demonstrating new use cases, filing bug reports, or even fixing bugs or adding functionality.\n\n\n\nThe fact that the whole ecosystem has been developed in the open, as an open source project, has contributed crucially to the success on several levels.\nIn the first place there is a large FOSS community in R that provides help, a packaging system, and also an infrastructure for developing, testing, documenting and publishing packages. The fact that this infrastructure, including the presence of a global informal and helpful community, exists has been extremely helpful during design and development of the packages. The usefulness of being able to directly contact the people who develop the infrastructure one is using is hard to overstate.\nSecondly, publishing the packages in open source immediately gives a large audience the opportunity to try the product: given enough eyeballs, all bugs are shallow  14. Enthusiastic users are able to contribute new use cases, issues, and documentation, which overall has contributed to creating more general and more robust software."
  },
  {
    "objectID": "case_studies.html#Istat",
    "href": "case_studies.html#Istat",
    "title": "Case Studies",
    "section": "Istat",
    "text": "Istat\nAdoption of OSS and governance efforts in Istat\nItalian National Institute of Statistics (Istat)\n\nIntroduction\nOutside of statistical software, Istat has a long experience of using open source software and already in 2004 an official working group on the use of open source software was formed. The group, made up of statistical and IT experts, studied the current uses of OS software and its potential developments. Under the impetus of the group, open source software spread throughout Istat, from Linux servers to connectivity software and various modules to support group work.\nAs for the statistical software, in the past Istat’s statistical work was carried out exclusively with SAS software, but for specific tasks some additional SAS tools had to be developed (e.g., MAUSS for deciding the optimal sample size and its allocation in multi-purpose surveys; GENESEES for weight calibration and estimation in sample surveys). For data processing and imputation, it was decided to use the SAS-based commercial tool BANFF, developed by Statistics Canada. Obviously, it was difficult to disseminate SAS-based tools to the members of the Italian National Statistical System (NSS) because, in most cases, they did not use SAS.\nThe introduction of R took place shortly after the year 2000, mainly in the Methodology Directorate, to test new methods; initially an informal group of R experts was created and met once a month; this group started to give workshops and occasional internal training (regular training started in 2007). These activities led to the identification of R as the preferred environment for developing new packages, also to replace tools developed in SAS or as stand-alone applications; the decision was also taken in response to a ministerial directive in April 2003, inviting government agencies to adopt open source software tools and avoid dependence on a single commercial software tool.\nThe first R packages were released around 2010 (ReGenesees for weights calibration and estimation; SamplingStrata for stratification and optimum allocation; SeleMix for selective editing; StatMatch for statistical matching), others followed later (e.g. FS4 for stratification, R2BEAT for determining optimal sample size and its allocation). In other cases, such as the RELAIS record linkage system, R became the engine for statistical computations. These packages were developed in the Methodology Directorate, and to facilitate their dissemination within the NSS and also externally, it was decided to create a repository on the corporate website 15. Packages to be included in the repository had to pass a rigorous approval procedure, which required the availability of clear documentation, a presentation to a committee and also the adoption of an EUPL licence, as recommended by the Istat Legal Office. Later, the licence requirements were relaxed and the GPL licence was also accepted, being the most popular in the R community. Some of the R packages are also distributed on CRAN and are easily accessible in the “Official Statistics” task view 16.\nToday, the activities related to R are focused on the maintenance of existing packages, which have recently experienced some disruptions due to the retirement of their developers/maintainers, and on the testing of already existing external packages (instead of developing new ones). For example, Istat is testing the R packages for data editing and imputation (validate, validatetools, errorlocate, simputation 17 and VIM) with the aim of adopting them to replace our obsolete standalone tool CONCORDJava. Similar tests are underway for disclosure control (R packages ptable and cellKey). Finally, we are working on extending the functionality of the R package RJDemetra, which provides the R interface to JDemetra+, the officially recommended seasonal adjustment software within the European Statistical System.\nR training for staff is provided regularly by in-house trainers; there are two “core” courses (“Base R” and “Intermediate R”) offered twice a year, and a number of short courses on specific topics/packages (e.g., the ggplot2 package) offered once a year. In addition, R tools are used in statistical courses (sampling, data integration, data processing and imputation, etc.) to demonstrate the application of methods. More generally, the developed packages and their improvements are promoted through presentations and tutorials at conferences/workshops, including the uRos 18 annual conference.\nRecently, research aimed at investigating the potential use of statistical learning and more generally machine learning techniques for official statistics, also with the aim of exploiting alternative data sources such as big data, led to the adoption of Python. As with R, the approach is bottom-up, as Python is mainly used in the Methodological Directorate. Python is currently being used to produce some experimental statistics: the Social Mood on Economy Index (SMEI) and the imporT ExpoRt networK Analysis (TERRA), a tool for exploratory analysis of Eurostat data on international trade. Other ongoing projects are quite diverse: web mining to integrate and validate information from the Statistical Business Register; estimation of road accidents using big data; estimation of urban greenery using remote sensing images; imputation of education levels in the Register of Persons; estimation of shipping routes, etc., although it is already being used to produce some experimental statistics. A few years ago, it was decided to organise Python courses (basic and advanced) for staff, offered once a year.\nToday, R and Python are the main languages used in the Methodology Directorate, but SAS remains the tool used in some technical units involved in the production of statistics. This is due to a number of factors: ageing staff in production units well trained in SAS and unwilling to lean and move to R; reduction of staff in production due to the inability to replace retired staff and consequently limited resources to ensure a complete migration from SAS to R; the fear of production managers of disrupting the publication of official statistics because of the introduction of new tools with limited support; and an absence of a structure ensuring support on R, contrary to what happens for SAS.\n\n\nGovernance\nFor these reasons, it was recently decided to increase efforts to ease the adoption of open source statistical tools in production directorates. The informal network of R experts will be expanded to include methodologists and subject matter experts with a solid knowledge of R and will become the official support structure for R from 2025 onwards. This network will also support the implementation of innovative methodologies (including the development of new packages) and the increase of training opportunities for staff. It should also contribute to the maintenance of packages already developed, also to avoid the problems recently experienced (i.e., the retirement of maintainers).\nA first part of the Istat policy for the governance of the statistical open source software tools is expected to be published by the end of 2024-early 2025. It will mainly deal with statistical-methodological aspects and provide some basic indications on the IT infrastructure, as the two elements are closely linked. The second part, more focused on IT infrastructure and IT requirements, will be published later.\nThe first part of the governance of statistical open source software will provide Istat researchers with a set of guidelines and recommended practices for the development of new tools or the adoption (and adaptation) of existing ones; finally, it will redesign the procedures for their approval and dissemination (including guidance on licensing) and maintenance over time.\nThe guidelines for the development of new open source statistical software will be published in late 2024 and will include recommendations for writing R code and documenting it according to international standards to facilitate code sharing and reuse. A second level of documentation, tailored for internal purposes only, will document the use of the tools in the specific production process to facilitate modifications/adaptations to specific circumstances encountered in a subsequent replication of the process.\nIn the development of the code, much attention is paid to dependency issues in order to limit problems related to changes/disruptions in the maintenance of the packages on which the code depends. This issue will be even more relevant for the adoption and possible adaptation of externally developed open source statistical tools; guidance will be provided on the procedure to be followed: criteria for selection among different potential candidates; preliminary checks to be performed (availability and clarity of documentation; maturity, frequency of updates and possible bug fixes; limitations and dependencies on other tools; available support, etc.); and testing procedures of the selected tools in case studies of increasing complexity. For both developed and acquired/adapted existing tools, the governance policy will provide guidance on their endorsement, dissemination and promotion internally and externally.\nGovernance will also provide recommendations for user support, maintenance and updating of the approved tools over time. All defined procedures should be complemented by the identification and establishment of a set of governance bodies with clearly defined roles and responsibilities."
  },
  {
    "objectID": "case_studies.html#SIS-CC",
    "href": "case_studies.html#SIS-CC",
    "title": "Case Studies",
    "section": "SIS-CC",
    "text": "SIS-CC\nBuilding a community-driven OSS: The SIS-CC experience\nOrganisation for Economic Co-operation and Development (OECD)\nThe statistical information system collaboration community (SIS-CC) is a reference open source community for official statistics, focusing on product excellence and delivering concrete solutions to common problems through co-investment and co-innovation.\n\nLicences\nSIS-CC’s adherence to the principles of openness and collaboration is embodied in its strategic choice to use the MIT licence for its open source tools. MIT is a permissive free software licence and places minimal restrictions on the reuse of code, thereby maximising flexibility and fostering an environment where innovation can thrive.\nThe decision to select MIT over alternative open source licences, such as Apache 2.0, is rooted in the desire for simplicity and minimal legal complexity. While both licences are permissive and encourage open contribution, there are differences that made MIT a better choice for SIS-CC. For example, the concise language and straightforward terms avoid legal jargon, making it very accessible for users to understand and implement correctly. There are fewer restrictions on the redistribution of software compared to Apache 2.0, which requires explicit attribution and changes documentation among other stipulations. With its minimalist approach, MIT is broadly compatible with other licences, allowing for greater interoperability of code across various projects and jurisdictions. It enables easier participation from the community because contributors do not need to worry about complex licence compliance, which can be more challenging with Apache 2.0. By opting for the MIT licence, the SIS-CC reduces the barriers to entry for users and contributors, thereby encouraging widespread adoption and collaboration on the open source project.\nWhile embracing the simplicity of MIT, SIS-CC also recognises the importance of managing contributions effectively. One mechanism for doing this is through Contributor Licence Agreements (CLAs) that clarifies the terms under which a contributor submits code or content to a project, protecting both the contributor and the organisation by ensuring that the intellectual property is appropriately managed. However, for SIS-CC, it was deemed too complex as it would add an unnecessary overhead to the contribution process, with the potential to deter casual contributors. Instead, the SIS-CC opted for a more automated and centrally controlled review and merge process whereby source code, reuse of libraries, and other components, are checked and validated for potential breaks in the licence chain. So far this has served the SIS-CC well and facilitated a number of contributions from outside of the core maintainers of the project.\n\n\nStandards\nThe SIS-CC plays a pivotal role in driving and promoting the adoption of global open standards within the statistical community, specifically focusing on the Statistical Data and Metadata Exchange (SDMX) and the Generic Statistical Business Process Model (GSBPM). These standards are essential for streamlined and accurate data management across diverse systems and organisations. Through the adoption of these standards, the SIS-CC has enhanced the efficiency, accuracy, and comparability of statistical data through standardised practices, fundamentally altering how data is managed and exchanged globally. Adopting these standards has increased efficiency and cost-effectiveness through streamlined data processes, fostered consistency and comparability in data across various systems, enhancing overall data integrity, and facilitated collaboration within a standardised framework that has simplified data sharing and collaboration among statistical organisations. The adoption of SDMX and GSBPM has prepared organisations to meet future data challenges and integrate into the global statistical ecosystem effectively. The SIS-CC’s robust initiative to standardised statistical practices has not only enhanced operational efficiencies within member organisations but also strengthened the global statistical community’s capability to handle modern data demands, fostering a more connected and resilient statistical landscape. SDMX’s role in facilitating a seamless communication and collaboration across not just statistical teams but also IT within organisations highlights its capacity to catalyse multidisciplinary teamwork, by automating data flows and enhancing user-friendly data exploration, which lays the groundwork for an efficient data-sharing environment.\nPowered by SDMX, the .Stat Suite, being the SIS-CC flagship product, has revolutionised how data is managed, processed, and disseminated from end-to-end, making it more accessible and easier for researchers and analysts to combine and connect in analytical work. The SIS-CC has already started to explore the integration of Artificial Intelligence (AI) with SDMX and the .Stat Suite which promises to unlock even more potential. As AI capabilities evolve, SDMX’s robust semantic framework can serve as a foundation for intelligent, automated data flows, and fostering innovations.\n\n\nKnowledge Building\nThe commitment of SIS-CC to enhancing data skills and knowledge led to the establishment of the .Stat Academy. This initiative represents a comprehensive effort to democratise access to self-paced online training, with a focus on enhancing the knowledge of data practitioners in data modelling and SDMX, as well as data toolers in the technologies and tools needed to support the statistical lifecycle. Through a diverse array of free online courses and resources, the .Stat Academy is empowering data professionals worldwide. It leverages a blended learning approach of online courses, hands-on workshops, and collaborative projects to facilitate learning. This multifaceted approach ensures that participants gain practical experience alongside theoretical knowledge. By offering courses on a wide range of topics, the .Stat Academy caters to varying levels of expertise and professional needs, fostering a vibrant, global community of data practitioners who share insights, challenges, and solutions, thus collectively advancing the field of statistical information systems.\n\n\nCulture\nThe journey from a closed community software development to an open source model represented a profound cultural shift for the SIS-CC. This evolution demanded a paradigm change, where openness, transparency, and collective engagement became the cornerstones of development. As SIS-CC members transitioned to open source practices, they embraced a culture that championed collaboration beyond organisational confines, paving the way for more innovative solutions. This shift confronted traditional viewpoints which emphasised proprietary control, urging a reorientation towards shared stewardship and a belief that pooling resources can lead to better outcomes.\nAdopting an open source culture necessitated overcoming numerous challenges. Developers had to recalibrate their approaches to software development—acknowledging that the broader community can contribute valuable insights and code improvements that no single entity could achieve alone. It required rethinking strategies around intellectual property, where inclusivity in innovation assumes priority over exclusivity. The shift to DevSecOps demanded a cultural overhaul where the team worked collaboratively across the entire development cycle, breaking down traditional silos. It required nurturing a mindset that places equal emphasis on speed and security, embedding security considerations from the onset of development rather than being an afterthought. To deal with the resistance that such a profound change brings demanded a concerted effort in training, change management, and the establishment of new norms.\n\n\nGovernance\nThe SIS-CC operates within a multi-tier community ecosystem, underpinning a sustainable business model that promotes co-innovation and co-investment. This multifaceted governance structure is essential for managing the dynamics of collaboration among diverse organisations and partners. Central to its governance is the multi-tier community ecosystem, meticulously designed to foster balanced user growth while ensuring the retention of agility and the maintenance of product excellence. This structure categorises members into different tiers based on the nature and extent of their contribution. Tier 1 organisations are pivotal, providing financial and in-kind contributions. This tier has the potential for receiving additional grants, reflecting a deep investment in the community and product advancement. Tier 2 organisations benefit either through commercial avenues or through institutional backing, like that provided by the ILO LMIS 19 project. This ensures a diverse range of organisational types and resources are contributing to and benefitting from the community. Tier 3 organisations access the Community products through self-service tools, such as Gitlab, documentation, the .Stat Academy, and issue tickets, enabling broader, more accessible participation.\nThe governance philosophy of the SIS-CC champions an inclusive strategy, laying its foundations on the Community Foundations: Community Driven Dynamics; Open source Delivery; Full Data Lifecycle; Componentised Architecture; and Systematic User Research. These foundations are critical in a shared journey towards achieving mutual objectives, enhancing collaboration, and solidifying our collective value proposition."
  },
  {
    "objectID": "case_studies.html#SORS",
    "href": "case_studies.html#SORS",
    "title": "Case Studies",
    "section": "SORS",
    "text": "SORS\nTransforming a software into OSS at SORS\nStatistical Office of the Republic of Serbia (SORS)\n\nIntroduction\nThe Statistical Office of the Republic of Serbia (SORS) has over the past 15 years developed the Istraživanje (IST) 20, a metadata driven statistical collection and production solution aligned with GSBPM, to meet the growing needs of statistical data processing in a rapidly evolving technological environment. The IST platform was developed in response to the complexity of statistical data handling, which requires a flexible, modular, and metadata-driven approach to ensure efficiency across the statistical lifecycle.\nSince its launch in 2006, IST has been deployed in several NSOs, including those in Kyrgyzstan, Montenegro, Bosnia and Herzegovina, and Albania. The platform was shared through Memorandums of Understanding (MoUs) and provided to partner NSOs as free software. As part of these agreements, SORS supplied the full source code and ongoing support, further demonstrating its commitment to international cooperation and statistical innovation. Over time, IST evolved through continuous feedback from these partners, further refining its features and capabilities.\nCollaborative Effort\nAlthough IST was entirely developed by SORS, its expansion and refinement were facilitated by collaborations with other NSOs. These partnerships enabled SORS to adapt IST to different country-specific contexts while ensuring that the core system remained robust, flexible, and adaptable. The software’s success lies in support for various file formats, languages, its modular design (which allows for integration with additional tools widespread among NSOs), and its comprehensive metadata management features that guide the statistical process from data collection to dissemination.\nKey Features of IST\nIST is a metadata-driven system designed to ensure seamless data management throughout the statistical process. Its architecture allows for real-time data entry, validation, and processing, making it an essential tool for modern statistical operations. The key features of IST include:\n\nMetadata-Driven Architecture: IST leverages metadata to control data processing workflows. This design ensures consistency and efficiency across different stages of data collection, validation, and analysis.\n\nModular Design: The platform’s architecture allows independent modules to be added or modified without affecting the entire system. This flexibility makes IST scalable and adaptable to various statistical requirements.\n\nAdvanced Reporting Capabilities: IST supports real-time reporting in multiple formats, such as Excel, JSON, CSV, TXT, and XML, facilitating easy data dissemination.\n\n\n\nSteps Toward Open Source\nIn recent years, SORS has recognised the importance of promoting open source solutions to foster collaboration and enhance the usability of IST across multiple regions. As part of this strategy, SORS has initiated a comprehensive plan to release IST as an open source product, adhering to widely accepted licensing and contribution practices.\nIST Productisation Steps\nThe transition to open source requires a structured and phased approach. In collaboration with international partners and legal experts, SORS is devising the plans for making IST open source:\n\nDefining Governance and Contribution Models: A key aspect of the open source transition is the establishment of clear governance models based on the foundations of openness, collaboration, and sustainability. SORS aims to implement a Contributor Licence Agreement (CLA) to ensure that all contributions are legally bound to be licenced back to SORS, preserving control over the project’s direction (lead by the Project Management Committee) while encouraging community contributions.\n\nTechnical Documentation and Support: IST’s open source version will be accompanied by comprehensive documentation, including user and developer manuals. SORS will continue to provide remote support to partner NSOs to ensure smooth implementation and adoption of the open source version.\n\nLicensing Strategy: Following a thorough review of different open source licences, SORS decided to use the Apache licence 2.0 with additional clauses to restrict the commercial redistribution of IST. This decision ensures that IST remains freely available for statistical offices and developers, while retaining legal protections over its intellectual property. The final decision will be made after thorough consideration by legal experts.\n\nPublishing and Maintenance: IST’s source code will be published on an open source platform, such as GitHub / GitLab, allowing for easy access and collaboration. The platform will also serve as a space for tracking issues, managing contributions, and providing updates.\n\n\n\nLicences\nTwo open source licences were considered for IST’s transition to open source: the MIT licence and the Apache licence 2.0. After careful evaluation, SORS opted for the Apache licence 2.0, which offers both permissive use and patent protection. This licence allows IST to be widely adopted while safeguarding SORS’s intellectual property rights.\nKey factors influencing this decision include:\n\nPatent Protection: Apache 2.0 includes an explicit patent grant, offering legal protection against patent-related disputes.\n\nBroad Usage and Modification Rights: The licence allows other statistical offices and developers to use, modify, and distribute IST, while ensuring that all modifications are licenced back to SORS.\n\nAttribution: All derivative works and redistributions must include an attribution notice recognizing SORS as the original developer.\n\nContributor Licence Agreement\nTo manage contributions effectively, SORS plans to implement a Contributor Licence Agreement (CLA). The CLA will ensure that all contributions to IST are licenced back to SORS, allowing the organisation to maintain control over the software’s development while promoting collaboration with the wider open source community.\nThe key elements of the CLA include:\n\nModification Rights: Contributors can modify IST for their internal use.\n\nNo Redistribution: Contributors are not allowed to redistribute IST or its modified versions to third parties.\n\nNo Commercial Use: IST and its derivatives cannot be used for commercial gain without explicit consent from SORS.\n\n\n\nConclusion\nThe transition of IST to an open source product represents a significant move by SORS to promote innovation and collaboration in the field of statistical data processing. While the specific licensing model for IST is still under consideration, SORS is carefully evaluating options, including the Apache licence 2.0, MIT and other permissive licence, to ensure the best balance between fostering global collaboration and protecting the integrity of the software.\nBy developing a flexible CLA, SORS aims to create a structured and collaborative environment where contributions from the broader statistical community, including universities, researchers, and developers, can enhance IST while ensuring its continued alignment with SORS’s goals. As the transition progresses, SORS remains committed to maintaining IST’s reputation as a modern, scalable, and secure solution for statistical data management, ensuring that it continues to meet the needs of NSOs worldwide."
  },
  {
    "objectID": "case_studies.html#Awesome-List",
    "href": "case_studies.html#Awesome-List",
    "title": "Case Studies",
    "section": "Awesome List for Official Statistics",
    "text": "Awesome List for Official Statistics\nSharing OSS across communities - The Awesome List for Official Statistics Software\nStatistics Netherlands\n\nIntroduction\nOpen source software offers significant benefits for producing official statistics, including cost savings, improved quality, greater flexibility, and the potential to foster standardisation. However, navigating the vast landscape of open source software packages already available within the statistical community can be challenging. Understanding which software exists, its maturity level, and its suitability for specific tasks is crucial for the reuse of statistical building blocks.\nTo address this challenge, in 2017 a number of conference participants including members of Statistics Netherlands started the awesome list of official statistics software 21. It is a community approach to facilitate knowledge sharing among statistical organisations and to promote the adoption of open source solutions. The list quickly grew from the software the initiators were involved in into an extensive catalogue of mature open source solutions in the ESS 22.\n\n\nExplanation of the awesome list of statistical software\nSharing statistical software among institutes has been a valuable practice for years, particularly in areas like disclosure control, data editing, collection, and dissemination. While a few well-established solutions have been widely adopted, the current software landscape for official statistics is far more complex and dynamic than in former years. Numerous specialised packages are continually being developed, making it challenging to maintain a comprehensive overview and increasing the risk of redundant development.\nTo address this issue, the awesome list of official statistics software was created, inspired by the popular concept of community-driven knowledge sharing in the ‘awesome list concept’ 23. This list serves as a valuable resource for discovering and utilising generic official statistics software. The list has grown significantly since its inception, now featuring over 130 open source packages that are readily available, well-maintained, and actively used by statistical offices worldwide. It includes packages for automated access to official statistics output and is itself developed and maintained in an open source spirit.\nThe concept of this list is not to replicate information but as much as possible to link to the information maintained by the respective open source developer(s). Hence, each entry on the list provides a link to the software download, a brief description, and essential metadata such as the latest version, last commit, and licence. This information is automatically extracted from the packaging system metadata, ensuring consistency and ease of use.\n\n\n\nFigure 1: Open source software on the awesome list\n\n\nTo provide users with a clear understanding of the software’s applications on the list, it is organised according to the Generic Statistical Business Process Model (GSBPM). Figure 2 illustrates the distribution of the 135 items across the various GSBPM processes.\n\n\n\nFigure 2: Software on the list by GSBPM\n\n\nFigure 3 shows the distribution of programming languages of items on the list. The vast majority of items are written in R, which shows the excellent software sharing methods in this community. Figure 4 shows the licences used on the list. GPL is the most popular licence followed by MIT and EUPL.\n\n\n\nFigure 3: The most popular programming languages among items on the list\n\n\n\n\n\nFigure 4: Open source licences of software on the list\n\n\n\n\nHow the awesome list contributes to the FOSS in official statistics\nThe list has proven to be a valuable tool for sharing knowledge about existing open source solutions among different user communities in the ESS, either methodologists, statisticians, IT specialists, or management 24. Suggestions for changes or additions come from statistical organisations around the world and functionality suggestions for adding compatibility information, maturity indicators, and popularity metrics are documented on the GitHub repository itself. Concluding we can say that this list, maintained by many, has already helped software reuse among statistical organisations and as long as the community actively uses and maintains it, it will continue this important role."
  },
  {
    "objectID": "case_studies.html#footnotes",
    "href": "case_studies.html#footnotes",
    "title": "Case Studies",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAlexander Kowarik, Mark van der Loo (2018). Using R in the statistical office: the experience of statistics Netherlands and Statistics Austria. Romanian Statistical Review 1/2018 15—29↩︎\nJ. Pannekoek, S. Scholtus, M. van der Loo (2013). Automated and manual data editing: a view on process design and methodology. Journal of Official Statistics 29 511-537↩︎\nMPJ van der Loo and E. de Jonge (2018) Statistical data cleaning with applications in R. John Wiley & Sons. ISBN: 978-1-118-89715-7↩︎\nhttps://www.nass.usda.gov/↩︎\nMPJ van der Loo, E de Jonge (2021). Data Validation Infrastructure for R. Journal of Statistical Software 1–22 97↩︎\nMPJ van der Loo, E de Jonge (2020). Data Validation. In Wiley StatsRef: Statistics Reference Online, pages 1-7. American Cancer Society↩︎\nE de Jonge E, MPJ van der Loo (2023). errorlocate: Locate Errors with Validation Rules. R package version 1.1.1, https://CRAN.R-project.org/package=errorlocate↩︎\nMPJ van der Loo, E de Jonge (2021). deductive: Data Correction and Imputation Using Deductive Methods. R package version 1.0.0, https://CRAN.R-project.org/package=deductive↩︎\nMPJ van der Loo (2024). Split-Apply-Combine with Dynamic Grouping. Journal of Statistical Software (Accepted for publication)↩︎\nMPJ van der Loo (2022). simputation: Simple Imputation. R package version 0.2.8, https://CRAN.R-project.org/package=simputation↩︎\nMPJ van der Loo (2021). Monitoring data in R with the lumberjack package. Journal of Statistical Software 98 1—11↩︎\nMark P.J. van der Loo (2021). A Method for Deriving Information from Running R Code. The R Journal 13 42–52↩︎\nvan der Laan, D. J. (2022). reclin2: a Toolkit for Record Linkage and Deduplication. R Journal, 14(2)↩︎\nLinus’s Law: https://en.wikipedia.org/wiki/Linus%27s_law↩︎\nhttps://www.istat.it/en/classifications-and-tools/methods-and-software-of-the-statistical-process/↩︎\nhttps://cloud.r-project.org/web/views/OfficialStatistics.html↩︎\nhttps://github.com/data-cleaning↩︎\nhttps://r-project.ro/conferences.html↩︎\nhttps://ilostat.ilo.org/resources/labour-market-information-systems/↩︎\nhttp://istportal.net↩︎\nhttps://github.com/SNStatComp/awesome-official-statistics-software↩︎\nOlav ten Bosch, Mark van der Loo, Alexander Kowarik, (2020), The awesome list of official statistical software: 100 … and counting, The Use of R in Official Statistics - uRos202↩︎\nAwesome list concept by Sindre Sorhus: https://github.com/sindresorhus/awesome↩︎\nM. van der Loo, O. ten Bosch, (2023), Free and Open Source Software at Statistics Netherlands, Conference of European Statisticians, Seventy-first plenary session, Geneva, 22-23 June 2023↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HLG-MOS Open Source Software",
    "section": "",
    "text": "Open-source software is essential for producing official statistics in an open, sharable, and transparent matter.\nThe following principles intended to guide both the production and adoption of open-source software for statistical production.\n\n\n\n\n\n\nOpen by default\n\n\n\n \n\n\n\n\nWork in the open\n\n\n\n \n\n\n\n\nImprove and give back\n\n\n\n \n\n\n\n\nThink generic building blocks\n\n\n\n\n\n\n\nTest, package and document\n\n\n\n \n\n\n\n\nChoose permissive\n\n\n\n \n\n\n\n\nPromote\n\n\n\n \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "major_topics.html",
    "href": "major_topics.html",
    "title": "Major Topics in OS and recommendations",
    "section": "",
    "text": "In this chapter, we dive into the core aspects of the open source ecosystem, which is not only about software but also involves a rich tapestry of legal, operational, and cultural dimensions. We explore six main topics:"
  },
  {
    "objectID": "major_topics.html#1.-licences-considerations",
    "href": "major_topics.html#1.-licences-considerations",
    "title": "Major Topics in OS and recommendations",
    "section": "1. Licences considerations",
    "text": "1. Licences considerations\nThe Open Source Initiative (https://opensource.org/licences) provides detailed information about all the officially approved open source licences. However, choosing an open source licence among these can still be tricky because it involves balancing multiple competing interests and considerations such as:\n\nLong-term implications: Your choice is often permanent and affects how your project can be used, modified, and distributed.\n\nLegal complexity: Different licences have subtle but important differences in terms of rights, obligations, and protections they provide.\n\nTrade-offs: You need to balance:\n\nProject adoption vs. control.\n\nCommercial potential vs. open source principles.\n\nProtection of your rights vs. user freedom.\n\n\nEcosystem considerations: Your choice needs to be compatible with:\n\nDependencies you’re using (components and software used).\n\nPlatforms you are targeting (Operating Systems, Clouds, CRAN, GitHub, …).\n\nCommunity expectations.\n\nLocal/regional considerations (like EUPL for European countries).\n\n\nOne important grouping is between “viral” and “permissive” licences. Viral/copyleft licences like GPL and EUPL require any derivative work to also be open source under the same licence, thus the licence requirements cascade throughout the entire project and its derivatives. Permissive licence like MIT and Apache on the other hand allow the code to be used in any way, including in closed-source projects, thus each user can choose their own licence. This implies different business impacts; viral licences can make commercial adoption more challenging and ensure ongoing openness while permissive licences are more business-friendly and allow others to create closed-source versions if desired.\nThe choice of open source license varies within the official statistical community, as highlighted by the license usage analysis 1 of tools in the Awesome List (see Case Studies: Awesome List). The most popular are GPL (approx. 50%), MIT (approx. 20%) and EUPL (approx. 15%). The choice of individual organisation is influenced by multiple factors.\nFor example, Istat mainly use the EUPL 1.1 licence (for some R tools developed by Istat are available under GPL license) for the following reasons:\n\nThe EUPL licence is the only licence translated in Italian.\n\nEUPL is the only licence “approved” and sponsored by European regulations and therefore legally valid in Italy.\n\nSIS-CC releases .STAT suite (see Case Studies: SIS-CC) under the MIT licence. They chose a permissive licence for following reasons:\n\nInternational collaboration: The MIT licence facilitates easy sharing and collaboration between statistical offices and organisations across different countries.\n\nPublic sector alignment: Many statistical organisations are public sector entities, and the MIT licence aligns well with government open source policies.\n\nIntegration flexibility: Statistical systems often need to integrate with various existing tools and systems - the MIT licence makes this legally straightforward.\n\nCommunity building: The permissive nature of the MIT licence encourages participation from a wide range of contributors.\n\nSORS at the current time is defining its open source policy (see Case Studies: SORS); they will use a permissive licence like Apache. As SORS wants to manage a community of NSOs working on its software tools, the reasons for choosing a permissive licence are similar to those of SIS-CC."
  },
  {
    "objectID": "major_topics.html#2.-standards",
    "href": "major_topics.html#2.-standards",
    "title": "Major Topics in OS and recommendations",
    "section": "2. Standards",
    "text": "2. Standards\nOpen source software (OSS) has strong connections with the adoption of open standards in different fields. The presence of established standards facilitates the adoption of OSS, while the use of OSS, in turn, promotes the broader adoption and development of those standards. Here some of standards that play important roles:\n\nProgramming languages:\n\nOpen source programming languages, in particular R, have been instrumental in the adoption of open source policies within national statistical offices (NSOs) by providing a trusted, versatile platform specifically tailored for statistical analysis and data processing. The ecosystem of R packages 2 supports a wide range of statistical and data science tasks, making it possible for NSOs to replace or complement proprietary software with reliable, community-validated tools. Additionally, the R community’s emphasis on reproducible research fosters a standardised approach to analysis and reporting, which enhances collaboration and long-term sustainability in NSOs’ statistical workflows.\n\nConsistency and Compatibility: Standardising on widely-used programming languages such as R and Python 3 ensures compatibility across various statistical and data science tools. These languages have extensive libraries and frameworks that simplify the integration of different tools and applications, making it easier for organisations to share and collaborate on code.\n\nCommunity and Ecosystem Support: Popular open source languages have large, active communities that continually expand and improve their ecosystems. This community support ensures regular updates, a wealth of resources, and broad compatibility, which is particularly valuable for organisations relying on open source tools.\n\nTraining and Knowledge Sharing: Adopting standardised programming languages streamlines training for new staff and facilitates knowledge sharing within and between organisations. Staff trained using Python or R can more easily adapt to similar environments, promoting a more unified skill set across NSOs, academia and other public agencies.\n\n\n\nData formats\n\nInteroperability Across Systems: Standard data formats like CSV 4, JSON 5, and XML 6 enable data to be shared and processed by multiple systems without extensive reformatting. Using open, well-documented data formats ensures that datasets remain accessible and usable across different platforms and applications, fostering smooth data exchange.\n\nLong-Term Accessibility and Data Preservation: Open data formats reduce the risk of data obsolescence and vendor lock-in. CSV and JSON, for instance, can be easily accessed and parsed by any software, which is crucial for long-term data usability. Open formats also ensure that future tools can read and interpret historical datasets without conversion issues.\n\nData Quality and Validation: Standardised data formats often come with tools or built-in capabilities for data validation, helping organisations maintain high data quality and consistency. For example, JSON and XML formats allow schema definitions that can be used to enforce data structure and integrity.\n\n\n\nExchange protocols\n\nGlobal Compatibility and Integration: Exchange protocols such as SDMX are specifically designed for statistical data, ensuring interoperability across statistical organisations globally. By adhering to these protocols, statistical offices can integrate their data with international platforms and share information that are compatible with other countries and organisations, facilitating global data collaboration and analysis. In the SDMX website there is a rich list of software tools 7 to support SDMX 8 implementers and developers. Also authentication and authorisation standard protocols like Oauth 9 can support the integration of systems.\n\nEfficient Data Sharing and Real-Time Access: Standard data exchange protocols, such as SDMX, RESTful APIs 10, and OData (Open Data Protocol 11), allow data to be accessed, shared, and updated in real time. These protocols make it easy for systems to communicate and exchange data quickly, which is essential for large-scale data dissemination and integration across different statistical platforms.\n\n\n\nModernStats standards\n\nBy adhering to UNECE ModernStats standards (e.g., GSBPM, GSIM), NSOs can build modular, compatible open source solutions that support efficient, standardised workflows and foster collaboration within the global statistical community.\n\nOpen source tools designed to align with GSBPM can fit seamlessly into existing workflows, as they adhere to recognised standards for data processing, validation, and analysis. The use of a common process model facilitates the adoption of compatible levels of granularity between different statistical packages.\n\nThe use of GSIM as common reference for metadata platforms increases the compatibility and the possibility of integration between software packages used in the different phases of the statistical process."
  },
  {
    "objectID": "major_topics.html#3.-culture",
    "href": "major_topics.html#3.-culture",
    "title": "Major Topics in OS and recommendations",
    "section": "3. Culture",
    "text": "3. Culture\nTransition to open source software requires cultural shifts in organisations, particularly if closed source/proprietary offerings have been the norm for a long period of time. In addition, the adoption of open-source principles demands a certain ethos and culture of work to be present within the organisation.\nSeveral common misconceptions about OSS contribute to hesitancy and resistance within organisations:\n\nOSS is of a lower quality as it is free (with the rationale that things that are paid for must be of higher quality or value).\n\nOSS is not seen to have the same level of support as that provided by vendors of proprietary software, who are responsible for ensuring their products quality and providing support if problems arise.\n\nOSS is changeable by anyone so there is no reliability or consistency in the tools.\n\nOSS is vulnerable to security threats, whereas proprietary software is safer given the commercial concerns of vendors (even though many organisations already use tools and software that are already built on OSS such as cloud computing solutions, security software).\n\nThese misconceptions, combined with existing organisational practices, contribute to cultural barriers and concerns that arise during the transition to OSS, such as:\n\nRisk aversion: If there are existing tools and software, changes are perceived as risky, especially by long standing staff and operational management, where the production of outputs may be considered to be at risk.\n\nResource concerns: NSOs may face challenges in allocating budgets for implementation, integration, and ongoing maintenance, underestimating the advantages that can come from shared development with other developers. A change in general requires resourcing, and an active decision to pursue. It is easier to allow passive indecision to propagate the status quo.\n\nInexperience with the wider OSS community, and the large-scale adoption of OSS across technical spheres.\n\nTrepidation about the capability required to maintain an internal code base, or tooling of versions adopted from OSS, or maintain a tool itself.\n\nPreference for stability and control: The dependency on proprietary tools may create a sense of comfort. The focus of open source tools is often on evolving features and flexibility, which can seem less stable or controlled to NSOs.\n\nAddressing these concerns is critical for NSOs to build a sustainable OSS culture across organisations. In the subsequent chapters, we discuss some of key challenges and strategies to address them through: knowledge building (Section 4), establishing governance (Section 5) and adopting security practices (Section 6)."
  },
  {
    "objectID": "major_topics.html#4.-knowledge-building",
    "href": "major_topics.html#4.-knowledge-building",
    "title": "Major Topics in OS and recommendations",
    "section": "4. Knowledge building",
    "text": "4. Knowledge building\nBelow are general recommendations for national statistical offices (NSOs) about knowledge sharing, based on the use cases provided and focusing on capacity building, documentation, and training:\nCapacity building through participating in collaborative networks:\n\nEncourage open source familiarity: Promote the adoption of widely-used open source tools like R and Python by integrating them into the organisation’s workflows. Use structured training programs to make the staff familiar with these tools and their applications in statistical work.\n\nEstablish centers of excellence: Create dedicated teams or units within the NSO to specialise in open source tools and methodologies. These teams can act as internal consultants, providing technical support and sharing expertise across departments.\n\nLeverage community collaboration: Actively participate in international and regional communities such as SIS-CC or open source forums to build institutional knowledge by learning from other NSOs’ experiences. Collaborative knowledge sharing accelerates capacity building and reduces redundant efforts.\n\nLeverage partnerships with academic institutions and international organisations to enhance knowledge transfer, ensuring access to the latest methodologies and technologies.\n\nExample: SIS-CC facilitates capacity building by aligning members around shared tools and standards like SDMX, promoting collective development and mutual learning.\nComprehensive and accessible documentation:\n\nDevelop and maintain comprehensive and consistent documentation for all statistical processes, methodologies, and software implementations. Use frameworks like GSIM to ensure structured documentation, enhancing clarity and usability for internal and external stakeholders.\n\nWhere possible, share documentation publicly to foster transparency and collaboration. This includes sharing metadata standards, data schemas, and technical manuals for open source tools used or developed by the NSO.\n\nRegularly update technical manuals and process documentation to ensure continuity, especially when staff turnover occurs. NSOs should prioritise institutionalising knowledge over reliance on individual expertise.\n\nUse open metadata standards such as DDI and SDMX to document statistical processes and data workflows comprehensively, enabling consistent understanding and reuse across organisations.\n\nExample: IST metadata-driven system by SORS supports standardised documentation, enhancing internal and regional knowledge sharing for effective statistical production.\nOngoing training and skill development:\n\nOffer regular training programs to build staff capacity in open source tools and modern statistical methodologies, ensuring teams remain adept at using and maintaining evolving technologies and methodologies.\n\nDesign training to address varied skill levels, from foundational workshops for beginners to advanced sessions for specialists that emphasises practical applications in statistical workflows. Modular training ensures staff across departments can develop relevant skills at their own pace.\n\nFor NSOs transitioning from proprietary to open source systems, implement mandatory training to ensure staff can effectively use and adapt to new tools. Istat’s systematic training for R users is an effective example.\n\nCollaborate with international organisations, universities, or private sector experts to access specialised training and knowledge-sharing opportunities.\n\nPromote a culture of peer-to-peer knowledge exchange:\n\nEncourage knowledge sharing between employees through internal forums, mentorship programs, or cross-departmental collaborations as well as organising workshops, hackathons, or collaborative projects where staff can work together on open source solutions, sharing insights and expertise. Such initiatives help disseminate expertise and bridge skill gaps across the organisation.\n\nCreate opportunities for staff to present their innovations and solutions internally and externally, fostering an environment where shared contributions are valued and rewarded.\n\nExample: The Data Clean ecosystem in Statistics Netherlands thrives on community contributions, enabling the exchange of modular, reusable tools that expand collective expertise.\nDevelop centralised knowledge repositories:\n\nImplement centralised knowledge repositories to store and share documentation, training materials, FAQs, case studies and user feedback, making these resources readily accessible to all staff and external collaborators. This ensures institutional knowledge is preserved.\n\nUse platforms like wikis, shared drives, or open source platforms to manage and distribute this information, ensuring continuity even when staff turnover occurs.\n\nExample: The Awesome List of Official Statistics Software acts as a shared resource for NSOs, providing a curated repository of open source tools and their applications.\nSupport open knowledge sharing practices externally:\n\nActively contribute to open source communities by sharing code, documentation, and lessons learned as well as by participating in relevant international, regional and national expert meetings (e.g., The Use of R in Official Statistics conferences 12). This practice not only helps the broader community but also positions the NSO as a leader in statistical innovation.\n\nExample: The SIS-CC’s .Stat Academy engages in sharing knowledge through online training, focusing on data modelling and SDMX. The availability of free training resources to support the statistical lifecycle acts as a powerful stimulus for the diffusion of open standards and software tools in the official statistics community."
  },
  {
    "objectID": "major_topics.html#5.-governance",
    "href": "major_topics.html#5.-governance",
    "title": "Major Topics in OS and recommendations",
    "section": "5. Governance",
    "text": "5. Governance\n\nThe two governance models\nIn the case-studies chapter we saw different governance models used by the projects: we could analyse them following the Cathedral and Bazaar models, defined by Eric S. Raymond in his influential essay, The Cathedral and the Bazaar.\nThe Cathedral model is a structured, centralised approach where a core team of developers maintains the control over the project, releasing updates after extensive internal testing to ensure stability and polish. The process is more closed, with limited involvement from the broader community until a version is ready for public release. This model emphasises planning, longer development cycles, and top-down decision-making.\nIn contrast, the Bazaar model is a decentralised, open approach that thrives on community participation and rapid iteration. Code is developed transparently, with contributors working simultaneously, often releasing small updates frequently. Decisions are made collaboratively, encouraging contributions from anyone, which allows the project to evolve quickly. This model embraces an agile, bottom-up development style that prioritises community feedback and adaptability over centralised control.\nComing to our use-cases, from one side we have the SIS-CC community (see Case Studies: SIS-CC), organised with Strategic Level Group, Management Level Group and Architecture Task Force, where the NSOs can choose among three different levels of participation and the development is supported by a defined vision and by a set of training courses available on the web.\nAt the other extreme we have communities like the Awesome List or the Data Cleaning communities (see Case Studies: Data Cleaning and Case Studies: The Awesome List), where users propose their own packages, there are no predefined strategies or developments, each user is free to test the products and possibly participate in their development. The community is held together only by the interest in software that can be used in the processes of official statistics organisations.\nAlso at the level of the NSOs, we can see two different governance models: the Serbian one (Case Studies: SORS) is more “structured”, the software released is controlled by the “official” structure and the developments are managed by the IT department in collaboration with the users. In Istat (Case Studies: Istat 3.2), the packages released are managed by a group of methodologists that publish their packages on public platforms and follow their development with a sort of volunteering.\n\n\nRecommendations on governance of open source software\nBelow we list some recommendations on governance that are valid for all models:\nDefine clear objectives for governance:\n\nEstablish a governance framework tailored to the NSO’s specific needs and objectives, ensuring alignment with statistical priorities such as data quality, security, and compliance.\n\nDefine which aspects of software development require centralised control (Cathedral) and which can benefit from community-driven contributions (Bazaar).\n\nEncourage stakeholder engagement:\n\nDevelop mechanisms to engage statisticians, IT experts, and external contributors in governance discussions.\n\nUse forums, workshops, and collaborative platforms to gather input on governance policies and software priorities.\n\nEstablish a supportive environment for external contributors by providing clear guidelines, documentation, and mentorship opportunities.\n\nApply governance models differently as needed:\n\nApply the Cathedral model to critical components such as data security, metadata management, and compliance tools while using the Bazaar model for auxiliary tools and add-ons.\n\nDistributed autonomy: delegate governance of less critical projects or extensions to trusted community members while retaining oversight over core functions.\n\nEstablish quality assurance processes:\n\nIntroduce robust quality assurance mechanisms to ensure all software contributions meet high standards for statistical accuracy, usability, documentation, and security.\n\nRequire peer reviews for contributions to Bazaar-style projects and maintain a centralised team for final validation.\n\nRisk management:\n\nDevelop a comprehensive risk management strategy to address potential issues such as untested contributions, security vulnerabilities, and dependency risks.\n\nRegularly audit community-driven code for vulnerabilities and integrate automated testing tools into the development pipeline.\n\nKnowledge building and sharing:\n\nProvide training for all NSO staff on OSS governance, development practices, and community engagement.\n\nFacilitate the exchange of experiences, challenges, and solutions among NSOs to improve OSS governance.\n\nCreate shared resources, such as guidelines for adopting and managing OSS, tailored to the needs of statistical organisations.\n\nTransparency in governance:\n\nPublish on the web governance policies, decision-making processes, and project roadmaps to ensure transparency and trust.\n\nClearly communicate the criteria for adopting, rejecting, or modifying community contributions.\n\nLeverage international standards and guidelines:\n\nEnsure that OSS governance aligns with international statistical standards, such as GSBPM, GSIM, and SDMX, to maintain consistency and interoperability.\n\nCollaborate with international organisations to standardise governance approaches and share collective expertise."
  },
  {
    "objectID": "major_topics.html#6.-security",
    "href": "major_topics.html#6.-security",
    "title": "Major Topics in OS and recommendations",
    "section": "6. Security",
    "text": "6. Security\nSecurity by obfuscation refers to the practice of relying on secrecy or obscurity of system details, such as source code or algorithms, to protect software or systems from threats. This practice provides a false sense of security and does not address underlying vulnerabilities. It can be easily circumvented by skilled attackers who can reverse-engineer the code.\nOpen source software takes a different approach to security. The source code is publicly available, allowing anyone to inspect, modify, and enhance it. This transparency can lead to more robust security for several reasons:\n\nMany eyes principle: The idea that “given enough eyeballs, all bugs are shallow” (called Linus’s Law) suggests that the more people who review the code, the more likely vulnerabilities will be discovered and fixed. This collaborative effort can lead to more secure software.\n\nCommunity contributions: Open source projects benefit from contributions from a global community of developers. This diverse input can lead to more innovative security solutions and faster identification of vulnerabilities.\n\nTransparency: Open source software promotes transparency, which builds trust among users. Users can verify the security of the software themselves or rely on community reviews and audits.\n\nRapid response: Open source communities can quickly respond to security issues. Once a vulnerability is identified, patches and updates can be developed and distributed rapidly.\n\nPeer review: Open source projects often undergo rigorous peer review processes. Code changes are scrutinised by multiple developers, reducing the likelihood of introducing new vulnerabilities.\n\nOpen source is no more a security risk than proprietary software, and due to the code being open to inspection there are grounds for arguing it is in fact more secure. However what it does have in common with proprietary software is a potential vulnerability to supply chain attacks. This is where rather than attacking the software itself, other packages (or services) imported or used are attacked instead. These may be proprietary or open source themselves. Defending against such attacks is too large a topic for discussion in this document, but no further security measures other than those that an organisation should be following regardless are required when using OSS in lieu of proprietary software.\nBelow are general recommendations for NSOs regarding security issues in adopting and developing open source software, with some references to the use cases presented. While these recommendations are interconnected, we present them separately to provide clarity and focus on specific aspects of security. Further discussion of security related issues can be found in Annex 2: SWOT analysis of OS adoption in NSOs of the HLG-MOS Open Source Software Project Report.\n\nSecure Adoption of Open Source Software Recommendations\n\nSecurity assessments:\n\nPerform regular security audits of open source software before adoption. Assess for vulnerabilities in dependencies, outdated libraries, and compliance with data protection laws (e.g., GDPR) or standards (e.g., ISO/IEC 27001). Where possible, automate package vulnerability scans in a CI/CD pipeline or internal package repository.\n\nTools: In the R-based ecosystem, managing third-party dependencies is critical; ensure packages are well-maintained and secure. Tools like SonarQube for static analysis or Snyk for dependency scanning can help identify vulnerabilities early.\n\n\nEstablish secure deployment practices:\n\nUse containerisation tools like Docker to isolate open source applications and ensure consistent and secure environments.\n\nProvide guidance on best practices for securely configuring and maintaining systems, as highlighted by the Awesome List use case.\n\nConsider adopting Configuration as Code (CaC) tools such as Ansible or Terraform to automate and enforce secure configurations.\n\n\nEnsure data confidentiality:\n\nImplement anonymisation and pseudonymisation techniques for sensitive data before processing it with open source tools. This is particularly important for platforms handling confidential statistical data.\n\nTools: Use tools like ARX for data anonymisation or OpenDP for implementing differential privacy to ensure data confidentiality.\n\n\nLeverage open source trustworthiness:\n\nUse software with permissive and well-documented licences (e.g., Apache 2.0 or MIT), as chosen by SORS and SIS-CC in the related case studies, ensuring no hidden restrictions or licensing issues compromise data security.\n\n\nInternational cooperation among NSOs:\n\nEnhance open source security by enabling shared expertise in code reviews, vulnerability identification, and the implementation of best practices. The collective effort ensures thorough scrutiny of software, reduces security risks, and promotes alignment with international standards.\n\nBy pooling resources and collaborating, NSOs build more robust and resilient open source solutions that benefit the global statistical community.\n\nTools: Collaboration platforms like Common Vulnerabilities and Exposures (CVE) or shared vulnerability databases can be leveraged to track and mitigate security threats across borders.\n\n\n\n\nSecure Development of Open Source Software Recommendations\n\nEmbed security in the development lifecycle:\n\nAdopt practices, like DevSecOps, to integrate security at every stage of the software development lifecycle. This ensures that vulnerabilities are addressed proactively rather than reactively, as emphasised by SIS-CC’s centralised review and merge process.\n\nUtilise tools like Jenkins with security plugins, and integrate automated security scanning in CI/CD pipelines.\n\n\nImplement contributor governance:\n\nUse Contributor Licence Agreements (CLAs) or similar governance tools to ensure all contributions to open source projects are secure, vetted, and legally compliant. This strategy is effective for ensuring that external contributions to tools like IST remain secure.\n\n\nLimit dependency risks and conduct supply chain security:\n\nWhile open source software presents numerous security benefits, it is susceptible to supply chain attacks. This involves attackers targeting external dependencies rather than the software itself.\n\nMinimise reliance on external libraries or ensure dependency management by selecting only well-maintained and frequently updated packages (Istat’s focus on dependency stability for R packages is an example of such preemptive security in development).\n\nMitigation strategies includes:\n\nRegularly assess dependencies for security patches and updates.\n\nRegularly scan for vulnerabilities in dependencies using tools like OWASP Dependency-Check or GitHub Dependabot.\n\nUse trusted repositories and verify cryptographic signatures for all third-party packages.\n\nEmploy strategies such as dependency pinning and careful management of version upgrades.\n\n\n\nMonitor threats and leverage community vetting:\n\nContinuously monitor for emerging threats within the open source ecosystem. Leverage tools like Threat Intelligence Platforms (TIPs) or community-driven security alerts to stay informed.\n\nEncourage open community feedback and peer review to identify and fix security vulnerabilities. The collaborative nature of the Data Clean ecosystem and the Awesome List ensures wider scrutiny and faster resolution of potential security issues.\n\n\nEstablish a clear incident response plan for addressing security vulnerabilities in open source software:\n\nThis should include guidelines for quickly patching vulnerabilities, communicating risks, and coordinating with affected stakeholders. Consider automated patch management systems to minimise response time."
  },
  {
    "objectID": "major_topics.html#footnotes",
    "href": "major_topics.html#footnotes",
    "title": "Major Topics in OS and recommendations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://observablehq.com/@olavtenbosch/visualizing-awesomeofficialstatistics-org↩︎\nThe best example is the software repository CRAN at https://cran.r-project.org/↩︎\nA good third-party software repository is the Python Project Index (PyPI) at https://pypi.org/↩︎\nAn awesome list: https://github.com/secretGeek/AwesomeCSV↩︎\nJSON resources can be found at https://github.com/burningtree/awesome-json?tab=readme-ov-file , https://ajv.js.org/ and https://www.json.org/json-en.html↩︎\nAn awesome list: https://github.com/StanimirIglev/awesome-xml↩︎\nTools for SDMX implementers and developers https://sdmx.org/?page_id=4500↩︎\nThe Bank for International Settlements publishes another website with SDMX resources at https://www.sdmx.io/↩︎\nhttps://oauth.net/2/↩︎\nAn Awesome list is available at https://github.com/marmelab/awesome-rest↩︎\nTools and resources can be found at https://www.odata.org/↩︎\nhttp://r-project.ro/conferences.html↩︎"
  }
]